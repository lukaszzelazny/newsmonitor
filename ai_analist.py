import os
import json
import numpy as np
from openai import OpenAI
from dotenv import load_dotenv
from collections import defaultdict
from database import Database, NewsArticle, AnalysisResult, TickerSentiment, Ticker, \
    SectorSentiment, BrokerageAnalysis
from sklearn.metrics.pairwise import cosine_similarity
from sqlalchemy import text

load_dotenv()

client = OpenAI(api_key=os.getenv('OPENAI_API', ''))

def load_patterns(filepath='patterns.json', name="relevant_patterns"):
    """Wczytuje atrybut 'relevant_patterns' z pliku JSON"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
            if name in data:
                return data[name]
            else:
                print(f"Brak klucza {name} w {filepath}, uÅ¼ywam domyÅ›lnych wzorcÃ³w")
                return None
    except FileNotFoundError:
        print(f"Brak pliku {filepath}, uÅ¼ywam domyÅ›lnych wzorcÃ³w")
        return None


# Wzorcowe frazy dla rÃ³Å¼nych kategorii istotnych newsÃ³w
RELEVANT_PATTERNS = load_patterns(name="revelant_patterns")
# Nieistotne wzorce
IRRELEVANT_PATTERNS = load_patterns(name="irrevelant_patterns")
NEGATIVE_KEYWORDS = load_patterns(name="negative_keywords")

NEWS_SUMMARY_PATTERN = load_patterns(name="summary_patterns")

def get_embedding(text: str, model: str = "text-embedding-3-large"):
    """
    Pobiera embedding dla danego tekstu.

    Args:
        text: Tekst do embedowania
        model: Model embeddings

    Returns:
        Lista float - wektor embedingu
    """
    text = text.replace("\n", " ").strip()
    if not text:
        return None

    try:
        response = client.embeddings.create(input=[text], model=model)
        return response.data[0].embedding
    except Exception as e:
        print(f"BÅ‚Ä…d podczas generowania embeddingu: {e}")
        return None


def calculate_relevance_score(news_embedding, pattern_embeddings):
    """
    Oblicza score istotnoÅ›ci na podstawie podobieÅ„stwa cosine.

    Args:
        news_embedding: Embedding newsa
        pattern_embeddings: Lista embeddings wzorcÃ³w

    Returns:
        Float - maksymalne podobieÅ„stwo (0-1)
    """
    if news_embedding is None or not pattern_embeddings:
        return 0.0

    news_emb = np.array(news_embedding).reshape(1, -1)

    max_similarity = 0.0
    for pattern_emb in pattern_embeddings:
        if pattern_emb is not None:
            pattern_arr = np.array(pattern_emb).reshape(1, -1)
            similarity = cosine_similarity(news_emb, pattern_arr)[0][0]
            max_similarity = max(max_similarity, similarity)

    return float(max_similarity)


def contains_pattern(pattern: list, title: str, content: str) -> tuple[bool, str]:
    """
    Sprawdza czy news zawiera sÅ‚owa kluczowe z listy pattern.
    
    Args:
        title: TytuÅ‚ artykuÅ‚u
        content: TreÅ›Ä‡ artykuÅ‚u
    
    Returns:
        Tuple[bool, str] - (czy_zawiera, znalezione_sÅ‚owo_kluczowe)
    """
    if not pattern:
        return False, ""
    
    # ÅÄ…czymy tytuÅ‚ i treÅ›Ä‡ w jeden tekst
    full_text = f"{title} {content or ''}".lower()
    
    # Sprawdzamy kaÅ¼de sÅ‚owo kluczowe
    for keyword in pattern:
        if keyword.lower() in full_text:
            return True, keyword
    
    return False, ""


def is_news_relevant(headline: str, lead: str, threshold: float = 0.65):
    """
    Sprawdza czy news jest istotny przy uÅ¼yciu embeddings.

    Args:
        headline: TytuÅ‚ artykuÅ‚u
        lead: TreÅ›Ä‡ artykuÅ‚u
        threshold: PrÃ³g istotnoÅ›ci (0-1)

    Returns:
        Tuple[bool, float, str] - (czy_istotny, score, powÃ³d)
    """
    # PoÅ‚Ä…cz tytuÅ‚ i lead
    full_text = f"{headline}. {lead}"

    # Pobierz embedding newsa
    news_embedding = get_embedding(full_text)
    if news_embedding is None:
        return False, 0.0, "BÅ‚Ä…d generowania embeddingu"

    # Generuj embeddingi dla wzorcÃ³w istotnych (cachowane w pamiÄ™ci)
    if not hasattr(is_news_relevant, '_relevant_cache'):
        print("GenerujÄ™ embeddingi wzorcÃ³w istotnych...")
        is_news_relevant._relevant_cache = {}
        for category, patterns in RELEVANT_PATTERNS.items():
            is_news_relevant._relevant_cache[category] = [
                get_embedding(pattern) for pattern in patterns
            ]

    # Generuj embeddingi dla wzorcÃ³w nieistotnych
    if not hasattr(is_news_relevant, '_irrelevant_cache'):
        print("GenerujÄ™ embeddingi wzorcÃ³w nieistotnych...")
        is_news_relevant._irrelevant_cache = [
            get_embedding(pattern) for pattern in IRRELEVANT_PATTERNS
        ]

    # Oblicz score dla kategorii istotnych
    category_scores = {}
    for category, embeddings in is_news_relevant._relevant_cache.items():
        score = calculate_relevance_score(news_embedding, embeddings)
        category_scores[category] = score

    max_relevant_score = max(category_scores.values()) if category_scores else 0.0
    best_category = max(category_scores,
                        key=category_scores.get) if category_scores else None

    # Oblicz score dla wzorcÃ³w nieistotnych
    irrelevant_score = calculate_relevance_score(
        news_embedding,
        is_news_relevant._irrelevant_cache
    )

    # Decyzja
    if irrelevant_score > 0.70:
        return False, irrelevant_score, f"Wykryto nieistotny wzorzec (score: {irrelevant_score:.3f})"

    if max_relevant_score >= threshold:
        return True, max_relevant_score, f"Kategoria: {best_category} (score: {max_relevant_score:.3f})"

    return False, max_relevant_score, f"{max_relevant_score:.3f} < {threshold}, {best_category}"


def save_not_analyzed(db: Database, news_id: int, reason: str, relevance_score: float):
    """
    Zapisuje informacjÄ™ o newsie, ktÃ³ry nie zostaÅ‚ przeanalizowany.

    Args:
        db: Instancja Database
        news_id: ID artykuÅ‚u
        reason: PowÃ³d nieprzeanalizowania
        relevance_score: Score istotnoÅ›ci
    """
    session = db.Session()
    try:
        session.execute(
            text("""
            INSERT INTO news_not_analyzed (news_id, reason, relevance_score)
            VALUES (:news_id, :reason, :relevance_score)
            ON CONFLICT (news_id) DO NOTHING
            """),
            {"news_id": news_id, "reason": reason, "relevance_score": relevance_score}
        )
        session.commit()
        print(f"âœ“ Zapisano do news_not_analyzed: ID={news_id}, powÃ³d: {reason}")
    except Exception as e:
        session.rollback()
        print(f"âœ— BÅ‚Ä…d zapisu do news_not_analyzed: {e}")
    finally:
        session.close()


PROMPT_NEWS = """
JesteÅ› doÅ›wiadczonym analitykiem gieÅ‚dowym.
Twoim zadaniem jest analizowaÄ‡ wiadomoÅ›ci ekonomiczne, gieÅ‚dowe i biznesowe
(np. z serwisu PAP Biznes) oraz oceniaÄ‡ ich potencjalne znaczenie rynkowe.

Zasady analizy:
1. **Rozpoznaj typ wiadomoÅ›ci**:
   - ğŸ¢ SpÃ³Å‚ka (dotyczy konkretnego podmiotu lub kilku spÃ³Å‚ek)
   - ğŸ­ Sektor (dotyczy branÅ¼y, np. banki, energetyka, gaming)
   - ğŸ’° Debiut / IPO (informacja o wejÅ›ciu spÃ³Å‚ki na gieÅ‚dÄ™)
   - ğŸ“Š Makro / Rynek (dotyczy ogÃ³lnych zjawisk gospodarczych)
   - ğŸ“‰ NiepowiÄ…zana / neutralna (nie ma znaczenia dla rynku)

   **WAÅ»NE - Emisja nowych akcji (ABB):**
   - JeÅ›li wiadomoÅ›Ä‡ dotyczy emisji nowych akcji, subskrypcji, ABB (akcelerowany budowa ksiÄ™gi), to ma to WYSOKI WPÅYW na kurs (zazwyczaj negatywny impact > 0.5)
   - Emisja akcji czÄ™sto powoduje rozwodnienie kapitaÅ‚u i spadek wartoÅ›ci akcji istniejÄ…cych akcjonariuszy
   - OceÅ„ impact na poziomie -0.6 do -0.8 dla standardowej emisji ABB
   - Confidence powinno byÄ‡ wysokie (0.8-0.9) dla tego typu wiadomoÅ›ci

2. **Zidentyfikuj tickery**:
   - JeÅ¼eli wiadomoÅ›Ä‡ dotyczy konkretnych spÃ³Å‚ek, zwrÃ³Ä‡ jeden gÅ‚Ã³wny ticker oraz ewentualnie inne powiÄ…zane.
   - JeÅ›li brak â€“ zwrÃ³Ä‡ pustÄ… listÄ™: `"related_tickers": []`.

3. **WAÅ»NE - ticker_impact**:
   - `ticker_impact` MUSI byÄ‡ POJEDYNCZÄ„ liczbÄ… od -1.0 do +1.0
   - Reprezentuje ÅšREDNI wpÅ‚yw na wszystkie wymienione spÃ³Å‚ki
   - JeÅ›li spÃ³Å‚ki majÄ… rÃ³Å¼ny wpÅ‚yw, oblicz Å›redniÄ… waÅ¼onÄ…
   - NIE uÅ¼ywaj obiektu z rÃ³Å¼nymi wartoÅ›ciami dla kaÅ¼dego tickera

4. **ZwrÃ³Ä‡ szczegÃ³lnÄ… uwagÄ™ na wyceny podawane przez domy maklerskie (DM)**:
   - JeÅ›li wystÄ™puje nowa wycena, wypisz:
     - nazwÄ™ domu maklerskiego,
     - starÄ… wycenÄ™,
     - nowÄ… wycenÄ™,
     - rekomendacjÄ™ (np. â€kupuj", â€neutralnie", â€sprzedaj"),
     - krÃ³tki komentarz.
   - JeÅ›li nie ma danych o wycenach â€“ wpisz wartoÅ›ci `null`.

5. **OceÅ„ wpÅ‚yw wiadomoÅ›ci**:
   - JeÅ›li wiadomoÅ›Ä‡ dotyczy spÃ³Å‚ki lub spÃ³Å‚ek:
     - `"ticker_impact"` â€“ POJEDYNCZA liczba od -1.0 do +1.0 (Å›redni wpÅ‚yw)
     - `"confidence"` â€“ 0.0â€“1.0 (pewnoÅ›Ä‡ oceny)
     - `"occasion"` â€“ `"krÃ³tkoterminowa"`, `"Å›rednioterminowa"` lub `"dÅ‚ugoterminowa"`
     - `"sector"` â€“ nazwa sektora
     - `"sector_impact"` â€“ `null`
   - JeÅ›li wiadomoÅ›Ä‡ nie zawiera tickerÃ³w, ale dotyczy sektora:
     - `"sector"` â€“ nazwa sektora
     - `"sector_impact"` â€“ liczba od -1.0 do +1.0
     - `"confidence"` â€“ 0.0â€“1.0
     - `"occasion"` â€“ `null`
     - `"ticker_impact"` â€“ `null`
   - JeÅ›li wiadomoÅ›Ä‡ jest neutralna:
     - Wszystkie pola wpÅ‚ywu (`ticker_impact`, `sector_impact`, `confidence`, `occasion`, `sector`) majÄ… wartoÅ›Ä‡ `null`.

6. **Dodaj krÃ³tkie uzasadnienie** w polu `"reason"` â€“ jedno lub dwa zdania.

7. **FORMAT ODPOWIEDZI**:
   - ZwrÃ³Ä‡ TYLKO czysty JSON, bez Å¼adnych komentarzy przed ani po
   - Bez dodatkowych wyjaÅ›nieÅ„ w stylu "*(Uwagi: ...)*"
   - Bez blokÃ³w markdown

---

### WejÅ›cie:
News:
"{headline}"
"{lead}"

### Oczekiwany wynik:
ZwrÃ³Ä‡ wyÅ‚Ä…cznie **poprawny JSON** w formacie:

{{
  "typ": "<Sektor / SpÃ³Å‚ka / Makro / IPO / Neutralna>",
  "related_tickers": ["..."],
  "sector": "<nazwa sektora lub null>",
  "ticker_impact": <POJEDYNCZA liczba lub null>,
  "sector_impact": <liczba lub null>,
  "confidence": <liczba lub null>,
  "occasion": "<typ okazji lub null>",
  "reason": "<krÃ³tkie wyjaÅ›nienie>",
  "brokerage_house": "<nazwa domu maklerskiego lub null>",
  "price_old": "<stara wycena lub null>",
  "price_new": "<nowa wycena lub null>",
  "price_recomendation": "<rekomendacja lub null>",
  "price_comment": "<komentarz do wyceny lub null>"
}}
"""


PROMPT_SUMMARY_FIXED = """
ğŸ§  Prompt PRO â€” analiza podsumowania dnia (zbioru newsÃ³w)

JesteÅ› doÅ›wiadczonym analitykiem gieÅ‚dowym.
Twoim zadaniem jest analizowaÄ‡ zbiorcze podsumowania wiadomoÅ›ci ekonomicznych, gieÅ‚dowych i biznesowych (np. z serwisu PAP Biznes lub Strefa InwestorÃ³w) i oceniaÄ‡ potencjalne znaczenie poszczegÃ³lnych informacji rynkowych.

Tekst, ktÃ³ry otrzymasz, moÅ¼e zawieraÄ‡ wiele krÃ³tkich newsÃ³w lub streszczeÅ„ w jednym artykule. KaÅ¼dy z nich potraktuj jako osobny wpis.
Dla kaÅ¼dego fragmentu (newsa) zastosuj poniÅ¼sze zasady analizy i zwrÃ³Ä‡ listÄ™ obiektÃ³w JSON â€“ po jednym dla kaÅ¼dej istotnej informacji.

Zasady analizy:

1. **Rozpoznaj typ wiadomoÅ›ci**:
   - ğŸ¢ SpÃ³Å‚ka â€“ dotyczy konkretnego podmiotu lub kilku spÃ³Å‚ek
   - ğŸ­ Sektor â€“ odnosi siÄ™ do caÅ‚ej branÅ¼y (np. banki, energetyka, gaming)
   - ğŸ’° Debiut / IPO â€“ informacja o wejÅ›ciu spÃ³Å‚ki na gieÅ‚dÄ™
   - ğŸ“Š Makro / Rynek â€“ dotyczy zjawisk gospodarczych, wskaÅºnikÃ³w, polityki pieniÄ™Å¼nej, cen surowcÃ³w, decyzji NBP/FED itp.
   - ğŸ“‰ NiepowiÄ…zana / Neutralna â€“ nie ma znaczenia dla rynku lub kursÃ³w akcji

   **WAÅ»NE - Emisja nowych akcji (ABB):**
   - JeÅ›li wiadomoÅ›Ä‡ dotyczy emisji nowych akcji, subskrypcji, ABB (akcelerowany budowa ksiÄ™gi), to ma to WYSOKI WPÅYW na kurs (zazwyczaj negatywny impact > 0.5)
   - Emisja akcji czÄ™sto powoduje rozwodnienie kapitaÅ‚u i spadek wartoÅ›ci akcji istniejÄ…cych akcjonariuszy
   - OceÅ„ impact na poziomie -0.6 do -0.8 dla standardowej emisji ABB
   - Confidence powinno byÄ‡ wysokie (0.8-0.9) dla tego typu wiadomoÅ›ci

2. **Zidentyfikuj tickery**:
   - JeÅ¼eli wiadomoÅ›Ä‡ dotyczy konkretnych spÃ³Å‚ek, wypisz ich tickery (np. "related_tickers": ["KGH", "PZU"])
   - JeÅ›li brak â€” zwrÃ³Ä‡ pustÄ… listÄ™: "related_tickers": []

3. **WAÅ»NE - ticker_impact**:
   - `ticker_impact` MUSI byÄ‡ POJEDYNCZÄ„ liczbÄ… od -1.0 do +1.0
   - Reprezentuje ÅšREDNI wpÅ‚yw na wszystkie wymienione spÃ³Å‚ki
   - JeÅ›li spÃ³Å‚ki majÄ… rÃ³Å¼ny wpÅ‚yw, oblicz Å›redniÄ… waÅ¼onÄ…
   - NIE uÅ¼ywaj obiektu z rÃ³Å¼nymi wartoÅ›ciami dla kaÅ¼dego tickera

4. **UwzglÄ™dnij nowe wyceny od domÃ³w maklerskich (DM)**:
   - JeÅ›li wystÄ™puje informacja o rekomendacji lub zmianie wyceny, wypisz:
     - "brokerage_house" â€“ nazwa domu maklerskiego
     - "price_old" â€“ stara wycena
     - "price_new" â€“ nowa wycena
     - "price_recomendation" â€“ np. "kupuj", "neutralnie", "sprzedaj"
     - "price_comment" â€“ krÃ³tki opis komentarza
     - "reason" â€“ uzasadnienie wpÅ‚ywu tej zmiany
   - JeÅ›li brak danych o wycenach â€” wpisz wartoÅ›ci null

5. **OceÅ„ wpÅ‚yw wiadomoÅ›ci**:
   - JeÅ›li dotyczy spÃ³Å‚ki/spÃ³Å‚ek:
     - "ticker_impact" â€“ POJEDYNCZA liczba od -1.0 do +1.0 (Å›redni wpÅ‚yw)
     - "confidence" â€“ liczba od 0.0 do 1.0
     - "occasion" â€“ "krÃ³tkoterminowa", "Å›rednioterminowa", "dÅ‚ugoterminowa"
     - "sector" â€“ nazwa sektora
     - "sector_impact" â€“ null
   - JeÅ›li dotyczy caÅ‚ego sektora:
     - "sector" â€“ nazwa sektora
     - "sector_impact" â€“ liczba od -1.0 do +1.0
     - "confidence" â€“ liczba od 0.0 do 1.0
     - "occasion" â€“ null
     - "ticker_impact" â€“ null
   - JeÅ›li wiadomoÅ›Ä‡ neutralna:
     - wszystkie pola wpÅ‚ywu (ticker_impact, sector_impact, confidence, occasion, sector) majÄ… wartoÅ›Ä‡ null

6. **Dodaj krÃ³tkie uzasadnienie** ("reason") â€“ jedno lub dwa zdania wyjaÅ›niajÄ…ce, dlaczego dana informacja moÅ¼e (lub nie moÅ¼e) wpÅ‚ynÄ…Ä‡ na rynek

7. **FORMAT ODPOWIEDZI**:
   - ZwrÃ³Ä‡ TYLKO czystÄ… tablicÄ™ JSON (array), bez Å¼adnych komentarzy
   - Bez dodatkowych wyjaÅ›nieÅ„ poza strukturÄ… JSON
   - Bez blokÃ³w markdown

---

### WejÅ›cie:
Podsumowanie dnia:
{news_summary_text}

### Oczekiwany wynik:
ZwrÃ³Ä‡ wyÅ‚Ä…cznie tablicÄ™ JSON (array) zawierajÄ…cÄ… obiekty â€“ kaÅ¼dy reprezentuje osobny news:

[
  {{
    "typ": "SpÃ³Å‚ka",
    "related_tickers": ["KGHM"],
    "sector": "surowce",
    "ticker_impact": 0.8,
    "sector_impact": null,
    "confidence": 0.9,
    "occasion": "Å›rednioterminowa",
    "reason": "Ceny miedzi wzrosÅ‚y po ograniczeniu eksportu z Chile, co sprzyja KGHM.",
    "brokerage_house": null,
    "price_old": null,
    "price_new": null,
    "price_recomendation": null,
    "price_comment": null
  }},
  {{
    "typ": "Sektor",
    "related_tickers": [],
    "sector": "banki",
    "ticker_impact": null,
    "sector_impact": -0.6,
    "confidence": 0.8,
    "occasion": null,
    "reason": "NBP zapowiedziaÅ‚ moÅ¼liwoÅ›Ä‡ obniÅ¼ki stÃ³p, co ogranicza marÅ¼e odsetkowe bankÃ³w.",
    "brokerage_house": null,
    "price_old": null,
    "price_new": null,
    "price_recomendation": null,
    "price_comment": null
  }}
]
"""

def analyze_summary(headline, lead):
    """
    Analizuje podsumowanie dnia (moÅ¼e zawieraÄ‡ wiele newsÃ³w) za pomocÄ… OpenAI API.

    Args:
        headline: TytuÅ‚ artykuÅ‚u
        lead: TreÅ›Ä‡/lead artykuÅ‚u (podsumowanie wielu newsÃ³w)

    Returns:
        JSON string z listÄ… analiz (array)
    """
    news_summary_text = f"{headline}\n\n{lead}"
    prompt = PROMPT_SUMMARY_FIXED.format(news_summary_text=news_summary_text)

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        # UWAGA: Dla tablicy JSON nie uÅ¼ywamy response_format
        # bo wymusza to zwracanie obiektu, nie array
    )
    return response.choices[0].message.content

def analyze_news(headline, lead):
    """
    Analizuje pojedynczy news za pomocÄ… OpenAI API.

    Args:
        headline: TytuÅ‚ artykuÅ‚u
        lead: TreÅ›Ä‡/lead artykuÅ‚u

    Returns:
        JSON string z wynikiem analizy
    """
    prompt = PROMPT_NEWS.format(headline=headline, lead=lead)

    response = client.chat.completions.create(
        model="gpt-4o",  # Zaktualizowana nazwa modelu
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}  # WymuÅ› JSON
    )
    return response.choices[0].message.content


def get_unanalyzed_articles(db: Database, exclude_not_analyzed: bool = True):
    """
    Pobiera artykuÅ‚y, ktÃ³re nie majÄ… jeszcze analizy.

    Args:
        db: Instancja Database
        exclude_not_analyzed: Czy wykluczyÄ‡ artykuÅ‚y z tabeli news_not_analyzed (domyÅ›lnie True)

    Returns:
        Lista obiektÃ³w NewsArticle
    """
    session = db.Session()
    try:
        # Wybierz artykuÅ‚y, ktÃ³re nie majÄ… wpisu w analysis_result
        query = session.query(NewsArticle).outerjoin(
            AnalysisResult, NewsArticle.id == AnalysisResult.news_id
        ).filter(AnalysisResult.id == None)

        # Opcjonalnie wykluczamy artykuÅ‚y z news_not_analyzed
        if exclude_not_analyzed:
            from database import NewsNotAnalyzed
            query = query.outerjoin(
                NewsNotAnalyzed, NewsArticle.id == NewsNotAnalyzed.news_id
            ).filter(NewsNotAnalyzed.id == None)

        articles = query.order_by(NewsArticle.id.desc()).all()
        return articles
    finally:
        session.close()

def get_article_by_id(db: Database, article_id: int):
    """
    Pobiera artykuÅ‚ po ID.

    Args:
        db: Instancja Database
        article_id: ID artykuÅ‚u

    Returns:
        Obiekt NewsArticle lub None
    """
    session = db.Session()
    try:
        return session.query(NewsArticle).filter(NewsArticle.id == article_id).first()
    finally:
        session.close()


def is_article_analyzed(db: Database, article_id: int) -> bool:
    """
    Sprawdza czy artykuÅ‚ zostaÅ‚ juÅ¼ przeanalizowany.

    Args:
        db: Instancja Database
        article_id: ID artykuÅ‚u

    Returns:
        True jeÅ›li artykuÅ‚ ma juÅ¼ analizÄ™, False w przeciwnym razie
    """
    session = db.Session()
    try:
        exists = session.query(AnalysisResult).filter(
            AnalysisResult.news_id == article_id
        ).first() is not None
        return exists
    finally:
        session.close()


def _save_single_analysis(session, news_id: int, analysis_data: dict, analysis_result_id: int):
    """
    Pomocnicza funkcja do zapisu pojedynczej analizy.

    Args:
        session: Sesja SQLAlchemy
        news_id: ID artykuÅ‚u
        analysis_data: Dict z danymi analizy
        analysis_result_id: ID utworzonego rekordu AnalysisResult
    """
    # Pobierz pola z JSON
    related_tickers = analysis_data.get('related_tickers', [])
    ticker_impact = analysis_data.get('ticker_impact')
    sector_impact = analysis_data.get('sector_impact')
    confidence_value = analysis_data.get('confidence')
    sector = analysis_data.get('sector')
    occasion = analysis_data.get('occasion')

    # Pola dla analiz domÃ³w maklerskich
    brokerage_house = analysis_data.get('brokerage_house')
    price_old = analysis_data.get('price_old')
    price_new = analysis_data.get('price_new')
    price_recommendation = analysis_data.get('price_recomendation')
    price_comment = analysis_data.get('price_comment')

    print(
        f"DEBUG: related_tickers={related_tickers}, ticker_impact={ticker_impact}, "
        f"sector_impact={sector_impact}, confidence={confidence_value}, sector={sector}, occasion={occasion}")

    # Najpierw dodaj tickery do sÅ‚ownika (jeÅ›li nie istniejÄ…)
    for ticker_symbol in related_tickers:
        existing_ticker = session.query(Ticker).filter(
            Ticker.ticker == ticker_symbol).first()
        if not existing_ticker:
            print(f"DEBUG: DodajÄ™ nowy ticker do sÅ‚ownika: {ticker_symbol}")
            new_ticker = Ticker(
                ticker=ticker_symbol,
                company_name=None,  # MoÅ¼e byÄ‡ uzupeÅ‚nione pÃ³Åºniej
                sector=sector
            )
            session.add(new_ticker)
        else:
            print(f"DEBUG: Ticker {ticker_symbol} juÅ¼ istnieje w sÅ‚owniku")

    # UtwÃ³rz ticker_sentiments (tylko jeÅ›li ticker_impact nie jest null)
    if related_tickers and ticker_impact is not None:
        for ticker_symbol in related_tickers:
            print(
                f"DEBUG: DodajÄ™ ticker_sentiment dla {ticker_symbol} z ticker_impact={ticker_impact}, "
                f"confidence={confidence_value}, occasion={occasion}")
            ticker_sentiment = TickerSentiment(
                analysis_id=analysis_result_id,
                ticker=ticker_symbol,
                sector=sector,
                impact=ticker_impact,  # Float z ticker_impact
                confidence=confidence_value,  # Confidence (0.0-1.0)
                occasion=occasion  # Typ okazji
            )
            session.add(ticker_sentiment)

    # Dodaj sector_sentiment (tylko jeÅ›li sector_impact nie jest null)
    if sector and sector_impact is not None:
        print(
            f"DEBUG: DodajÄ™ sector_sentiment dla sektora: {sector} z sector_impact={sector_impact}, "
            f"confidence={confidence_value}")
        sector_sentiment = SectorSentiment(
            analysis_id=analysis_result_id,
            sector=sector,
            impact=sector_impact,  # Float z sector_impact
            confidence=confidence_value  # Confidence (0.0-1.0)
        )
        session.add(sector_sentiment)

    # Dodaj BrokerageAnalysis (tylko jeÅ›li brokerage_house nie jest puste/null)
    if brokerage_house:
        # JeÅ›li jest brokerage_house, powinien byÄ‡ co najmniej jeden ticker
        ticker_for_brokerage = related_tickers[0] if related_tickers else None
        print(
            f"DEBUG: DodajÄ™ BrokerageAnalysis: {brokerage_house} dla {ticker_for_brokerage}")
        brokerage_analysis = BrokerageAnalysis(
            analysis_id=analysis_result_id,
            ticker=ticker_for_brokerage,
            brokerage_house=brokerage_house,
            price_old=price_old,
            price_new=price_new,
            price_recommendation=price_recommendation,
            price_comment=price_comment
        )
        session.add(brokerage_analysis)


def save_analysis_results(db: Database, news_id: int, analysis_json: str):
    """
    Zapisuje wyniki analizy do bazy danych.
    ObsÅ‚uguje zarÃ³wno pojedynczÄ… analizÄ™ (obiekt JSON), jak i listÄ™ analiz (array JSON).

    Args:
        db: Instancja Database
        news_id: ID artykuÅ‚u
        analysis_json: JSON string z wynikiem analizy (obiekt lub array)

    Returns:
        ID utworzonego rekordu AnalysisResult (dla pojedynczej analizy)
        lub lista ID (dla listy analiz)
    """
    session = db.Session()
    try:
        # UsuÅ„ potencjalny blok markdown z JSON
        cleaned_json = cleanJson(analysis_json)

        # Parsuj JSON
        print(f"DEBUG: Parsing JSON: {cleaned_json[:200]}...")
        analysis_data = json.loads(cleaned_json)

        # SprawdÅº czy analysis_data jest listÄ… (podsumowanie) czy pojedynczym obiektem (pojedynczy news)
        if isinstance(analysis_data, list):
            print(f"DEBUG: Wykryto listÄ™ analiz ({len(analysis_data)} elementÃ³w)")
            # To jest lista analiz - podsumowanie dnia
            analysis_ids = []
            for idx, single_analysis in enumerate(analysis_data):
                print(f"DEBUG: Przetwarzam analizÄ™ {idx + 1}/{len(analysis_data)}")

                # UtwÃ³rz osobny wpis w analysis_result dla kaÅ¼dej analizy
                analysis_result = AnalysisResult(
                    news_id=news_id,
                    summary=json.dumps(single_analysis, ensure_ascii=False)
                )
                session.add(analysis_result)
                session.flush()  # Aby uzyskaÄ‡ ID
                print(f"DEBUG: Utworzono AnalysisResult z ID={analysis_result.id}")

                # Zapisz pojedynczÄ… analizÄ™
                _save_single_analysis(session, news_id, single_analysis, analysis_result.id)
                analysis_ids.append(analysis_result.id)

            session.commit()
            print(f"DEBUG: Commit wykonany pomyÅ›lnie - zapisano {len(analysis_ids)} analiz")
            return analysis_ids  # ZwrÃ³Ä‡ listÄ™ ID
        else:
            print(f"DEBUG: Wykryto pojedynczÄ… analizÄ™")
            # To jest pojedyncza analiza
            analysis_result = AnalysisResult(
                news_id=news_id,
                summary=cleaned_json
            )
            session.add(analysis_result)
            session.flush()  # Aby uzyskaÄ‡ ID
            print(f"DEBUG: Utworzono AnalysisResult z ID={analysis_result.id}")

            # Zapisz pojedynczÄ… analizÄ™
            _save_single_analysis(session, news_id, analysis_data, analysis_result.id)

            session.commit()
            print(f"DEBUG: Commit wykonany pomyÅ›lnie")
            return analysis_result.id
    except json.JSONDecodeError as e:
        session.rollback()
        raise ValueError(f"Nie moÅ¼na sparsowaÄ‡ JSON: {e}")
    except Exception as e:
        session.rollback()
        raise e
    finally:
        session.close()


def cleanJson(analysis_json: str) -> str:
    """
    CzyÅ›ci JSON z markdown blokÃ³w i dodatkowych komentarzy.
    
    Args:
        analysis_json: Surowy string JSON z odpowiedzi API
        
    Returns:
        Wyczyszczony string JSON
    """
    cleaned_json = analysis_json.strip()
    
    # UsuÅ„ markdown bloki (```json ... ```)
    if cleaned_json.startswith('```'):
        lines = cleaned_json.split('\n')
        # ZnajdÅº poczÄ…tek i koniec bloku
        start_idx = 0
        end_idx = len(lines)
        
        for i, line in enumerate(lines):
            if line.strip().startswith('```'):
                if start_idx == 0:
                    start_idx = i + 1
                else:
                    end_idx = i
                    break
        
        cleaned_json = '\n'.join(lines[start_idx:end_idx])
    
    # UsuÅ„ komentarze po JSON (wszystko po zamykajÄ…cym } lub ])
    # Szukamy ostatniego } lub ] ktÃ³ry koÅ„czy gÅ‚Ã³wnÄ… strukturÄ™
    cleaned_json = cleaned_json.strip()
    
    # SprawdÅº czy to array czy obiekt
    if cleaned_json.startswith('['):
        # Dla array, szukamy ostatniego ]
        last_bracket = cleaned_json.rfind(']')
        if last_bracket != -1:
            cleaned_json = cleaned_json[:last_bracket + 1]
    else:
        # Dla obiektu, szukamy ostatniego }
        last_brace = cleaned_json.rfind('}')
        if last_brace != -1:
            cleaned_json = cleaned_json[:last_brace + 1]
    
    return cleaned_json.strip()


def analyze_articles(db: Database, mode: str = 'unanalyzed', article_id: int = None,
                     relevance_threshold: float = 0.50, telegram=None, skip_relevance_check: bool = False):
    """
    GÅ‚Ã³wna funkcja do analizy artykuÅ‚Ã³w z wstÄ™pnÄ… filtracjÄ… istotnoÅ›ci.

    Args:
        db: Instancja Database
        mode: 'id' (dla konkretnego ID) lub 'unanalyzed' (dla nieprzeanalizowanych)
        article_id: ID artykuÅ‚u (wymagane gdy mode='id')
        relevance_threshold: PrÃ³g istotnoÅ›ci dla embeddings (0-1)
        telegram: Instancja Telegram do wysyÅ‚ania powiadomieÅ„
        skip_relevance_check: JeÅ›li True, pomija sprawdzanie wzorcÃ³w i od razu analizuje przez AI

    Returns:
        Dict z informacjÄ… o przetworzonych artykuÅ‚ach
    """
    articles = []

    if mode == 'id':
        if article_id is None:
            raise ValueError("Dla trybu 'id' musisz podaÄ‡ article_id")
        print(f"Szukam artykuÅ‚u o ID={article_id}...")
        article = get_article_by_id(db, article_id)
        if article:
            articles = [article]
            print(f"Znaleziono artykuÅ‚: {article.title[:80]}")
        else:
            print(f"Nie znaleziono artykuÅ‚u o ID={article_id}")
            return {"status": "error",
                    "message": f"Nie znaleziono artykuÅ‚u o ID={article_id}"}
    elif mode == 'unanalyzed':
        print("Szukam nieprzeanalizowanych artykuÅ‚Ã³w...")
        articles = get_unanalyzed_articles(db)
        print(f"Znaleziono {len(articles)} nieprzeanalizowanych artykuÅ‚Ã³w")
    else:
        raise ValueError(f"NieprawidÅ‚owy tryb: {mode}. UÅ¼yj 'id' lub 'unanalyzed'")

    if not articles:
        print("Brak artykuÅ‚Ã³w do analizy")
        return {"status": "success", "message": "Brak artykuÅ‚Ã³w do analizy",
                "not_relevant" : 0,
                "analyzed": 0}

    results = []
    analysis_json = None
    for article in articles:
        try:
            print(f"\n=== Przetwarzam artykuÅ‚ ID={article.id}: {article.title[:50]}...")

            # SprawdÅº czy artykuÅ‚ juÅ¼ zostaÅ‚ przeanalizowany
            if is_article_analyzed(db, article.id):
                print(
                    f"âŠ˜ ArtykuÅ‚ ID={article.id} zostaÅ‚ juÅ¼ wczeÅ›niej przeanalizowany - pomijam")
                results.append({
                    "article_id": article.id,
                    "title": article.title,
                    "status": "skipped",
                    "reason": "already_analyzed"
                })
                continue

            # NOWE: WstÄ™pna analiza istotnoÅ›ci (POMIJANA jeÅ›li skip_relevance_check=True)
            if skip_relevance_check:
                print(f"[1/2] Pomijam sprawdzanie wzorcÃ³w - bezpoÅ›rednia analiza AI...")
                has_summary = False
                is_relevant = True
                relevance_score = 1.0
            else:
                print(f"[1/3] Sprawdzam istotnoÅ›Ä‡ newsa...")

                # SprawdÅº czy news zawiera negatywne sÅ‚owa kluczowe
                has_negative, negative_keyword = contains_pattern(NEGATIVE_KEYWORDS, article.title, article.content or "")
                if has_negative:
                    reason = f"Zawiera negatywne sÅ‚owo kluczowe: '{negative_keyword}'"
                    print(f"    âœ— Wykluczony: {reason}")
                    save_not_analyzed(db, article.id, reason, 0.0)
                    results.append({
                        "article_id": article.id,
                        "title": article.title,
                        "status": "skipped",
                        "reason": "negative_keyword",
                        "relevance_score": 0.0,
                        "details": reason
                    })
                    continue
                has_summary, summary_keyword = contains_pattern(NEWS_SUMMARY_PATTERN,
                                                                  article.title,
                                                                  article.content or "")
                if not has_summary:
                    is_relevant, relevance_score, relevance_reason = is_news_relevant(
                        article.title,
                        article.content or "",
                        threshold=relevance_threshold
                    )
                else:
                    is_relevant, relevance_score, relevance_reason = True, 1, "Podsumowanie dnia"

                print(
                    f"    IstotnoÅ›Ä‡: {'TAK' if is_relevant else 'NIE'} (score: {relevance_score:.3f})")
                print(f"    PowÃ³d: {relevance_reason}")

                if not is_relevant:
                    # Zapisz do news_not_analyzed
                    save_not_analyzed(db, article.id, relevance_reason, relevance_score)
                    results.append({
                        "article_id": article.id,
                        "title": article.title,
                        "status": "skipped",
                        "reason": "not_relevant",
                        "relevance_score": relevance_score,
                        "details": relevance_reason
                    })
                    continue

            # Analizuj artykuÅ‚ (tylko jeÅ›li jest istotny lub skip_relevance_check=True)
            step_num = "[2/2]" if skip_relevance_check else "[2/3]"
            print(f"{step_num} WysyÅ‚am zapytanie do OpenAI...")
            if has_summary:
                analysis_json = analyze_summary(article.title, article.content or "")
                analysis_datas = json.loads(cleanJson(analysis_json))
                for analysis_data in analysis_datas:
                    tickers = analysis_data.get('related_tickers', [])
                    ticker_impact = analysis_data.get('ticker_impact')
                    sector = analysis_data.get('sector')
                    sector_impact = analysis_data.get('sector_impact')
                    if tickers and ticker_impact and ticker_impact != 0:
                        telegram.send_analysis_alert(ticker=','.join(tickers),
                                                     title=article.title,
                                                     reason=analysis_data.get('reason'),
                                                     impact=ticker_impact,
                                                     confidence=analysis_data.get(
                                                         'confidence')
                                                     )
                    elif sector and sector_impact:
                        telegram.send_sector_alert(sector=sector,
                                                   title=article.title,
                                                   reason=analysis_data.get('reason'),
                                                   impact=sector_impact,
                                                   confidence=analysis_data.get(
                                                       'confidence')
                                                   )

            else:
                analysis_json = analyze_news(article.title, article.content or "")
                analysis_data = json.loads(cleanJson(analysis_json))
                tickers = analysis_data.get('related_tickers', [])
                sector_impact = analysis_data.get('sector_impact')
                sector = analysis_data.get('sector')
                if tickers and telegram:
                    telegram.send_analysis_alert(ticker=','.join(tickers),
                                                 title=article.title,
                                                 reason=analysis_data.get('reason'),
                                                 impact=analysis_data.get('ticker_impact'),
                                                 confidence=analysis_data.get('confidence')
                                                 )
                elif sector and telegram:
                    telegram.send_sector_alert(sector=sector,
                                                 title=article.title,
                                                 reason=analysis_data.get('reason'),
                                                 impact=sector_impact,
                                                 confidence=analysis_data.get('confidence')
                                                 )
            print(f"    Otrzymano odpowiedÅº: {analysis_json[:100]}...")

            # Zapisz wyniki
            step_num = "[2/2]" if skip_relevance_check else "[3/3]"
            print(f"{step_num} ZapisujÄ™ wyniki do bazy danych...")

            analysis_id = save_analysis_results(db, article.id, analysis_json)
            print(f"âœ“ PomyÅ›lnie zapisano analizÄ™ (analysis_id={analysis_id})")

            results.append({
                "article_id": article.id,
                "analysis_id": analysis_id,
                "title": article.title,
                "status": "success",
                "relevance_score": relevance_score
            })
        except Exception as e:
            print(f"âœ— BÅÄ„D podczas analizy artykuÅ‚u ID={article.id}, json={analysis_json}: {str(e)}")
            import traceback
            traceback.print_exc()
            results.append({
                "article_id": article.id,
                "title": article.title,
                "status": "error",
                "error": str(e)
            })

    success_count = sum(1 for r in results if r['status'] == 'success')
    skipped_count = sum(1 for r in results if r['status'] == 'skipped')
    not_relevant_count = sum(1 for r in results if r.get('reason') == 'not_relevant')
    error_count = sum(1 for r in results if r['status'] == 'error')

    print(f"\n{'=' * 60}")
    print(f"PODSUMOWANIE:")
    print(f"  Przeanalizowane:     {success_count}")
    print(f"  PominiÄ™te (juÅ¼ byÅ‚y): {skipped_count - not_relevant_count}")
    print(f"  Odrzucone (nieistotne): {not_relevant_count}")
    print(f"  BÅ‚Ä™dy:               {error_count}")
    print(f"{'=' * 60}\n")

    return {
        "status": "completed",
        "analyzed": success_count,
        "skipped": skipped_count - not_relevant_count,
        "not_relevant": not_relevant_count,
        "errors": error_count,
        "results": results
    }


def calculate_trends(news_list):
    """
    Oblicza trendy sektorowe na podstawie ocen newsÃ³w.
    KaÅ¼dy element listy powinien mieÄ‡ pola:
    - 'sector': str
    - 'impact': float  (od -1 do 1)
    - 'confidence': float  (od 0 do 1)
    """

    # grupowanie po sektorach
    sectors = defaultdict(list)
    for n in news_list:
        if n.get("sector") and n.get("impact") is not None:
            weighted = n["impact"] * n.get("confidence", 1.0)
            sectors[n["sector"]].append(weighted)

    # liczymy Å›redni trend dla kaÅ¼dego sektora
    summary = []
    for sector, weights in sectors.items():
        avg = sum(weights) / len(weights)

        # klasyfikacja trendu
        if avg > 0.15:
            momentum = "rosnÄ…ce"
        elif avg < -0.15:
            momentum = "malejÄ…ce"
        else:
            momentum = "neutralne"

        summary.append({
            "sector": sector,
            "trend_score": round(avg, 3),
            "momentum": momentum,
            "count": len(weights)
        })

    # sortowanie po sile trendu (od najwyÅ¼szego do najniÅ¼szego)
    summary.sort(key=lambda x: x["trend_score"], reverse=True)
    return summary


def get_sector_report(db: Database):
    """
    Generuje raport trendÃ³w dla sektorÃ³w na podstawie danych z tabeli sector_sentiment.

    Args:
        db: Instancja Database

    Returns:
        Lista sÅ‚ownikÃ³w z trendami sektorowymi
    """
    session = db.Session()
    try:
        # Pobierz wszystkie wpisy z sector_sentiment
        sentiments = session.query(SectorSentiment).all()

        # PrzeksztaÅ‚Ä‡ do formatu wymaganego przez calculate_trends
        news_list = []
        for sentiment in sentiments:
            if sentiment.sector and sentiment.impact is not None:
                try:
                    impact_value = float(sentiment.impact)
                    confidence_value = sentiment.confidence if sentiment.confidence is not None else 1.0

                    news_list.append({
                        "sector": sentiment.sector,
                        "impact": impact_value,
                        "confidence": confidence_value
                    })
                except (ValueError, TypeError):
                    # PomiÅ„ nieprawidÅ‚owe wartoÅ›ci
                    continue

        # UÅ¼yj calculate_trends do obliczenia raport
        return calculate_trends(news_list)
    finally:
        session.close()


def get_ticker_report(db: Database):
    """
    Generuje raport trendÃ³w dla tickerÃ³w na podstawie danych z tabeli ticker_sentiment.

    Args:
        db: Instancja Database

    Returns:
        Lista sÅ‚ownikÃ³w z trendami dla tickerÃ³w
    """
    session = db.Session()
    try:
        # Pobierz wszystkie wpisy z ticker_sentiment
        sentiments = session.query(TickerSentiment).all()

        # Grupowanie po tickerach
        tickers = defaultdict(list)
        for sentiment in sentiments:
            if sentiment.ticker and sentiment.impact is not None:
                try:
                    impact_value = float(sentiment.impact)
                    confidence_value = sentiment.confidence if sentiment.confidence is not None else 1.0
                    weighted = impact_value * confidence_value
                    tickers[sentiment.ticker].append(weighted)
                except (ValueError, TypeError):
                    continue

                # Liczymy Å›redni trend dla kaÅ¼dego tickera
                summary = []
                for ticker, weights in tickers.items():
                    avg = sum(weights) / len(weights)

                    # Klasyfikacja trendu
                    if avg > 0.15:
                        momentum = "pozytywny"
                    elif avg < -0.15:
                        momentum = "negatywny"
                    else:
                        momentum = "neutralny"

                    summary.append({
                        "ticker": ticker,
                        "trend_score": round(avg, 3),
                        "momentum": momentum,
                        "count": len(weights)
                    })

                # Sortowanie po sile trendu
                summary.sort(key=lambda x: x["trend_score"], reverse=True)
                return summary

    finally:
        session.close()

def generate_report(db: Database):
    """
    Generuje peÅ‚ny raport zawierajÄ…cy trendy dla sektorÃ³w i tickerÃ³w.

    Args:
        db: Instancja Database

    Returns:
        Dict z raportami dla sektorÃ³w i tickerÃ³w
    """
    print("\n" + "="*60)
    print("GENEROWANIE RAPORTU ANALIZ")
    print("="*60)

    # Raport dla sektorÃ³w
    print("\n[1/2] GenerujÄ™ raport dla sektorÃ³w...")
    sector_report = get_sector_report(db)
    print(f"âœ“ Znaleziono {len(sector_report)} sektorÃ³w")

    # Raport dla tickerÃ³w
    print("\n[2/2] GenerujÄ™ raport dla spÃ³Å‚ek (tickerÃ³w)...")
    ticker_report = get_ticker_report(db)
    print(f"âœ“ Znaleziono {len(ticker_report)} tickerÃ³w")

    report = {
        "sectors": sector_report,
        "tickers": ticker_report
    }

    # WyÅ›wietl podsumowanie
    print("\n" + "="*60)
    print("RAPORT SEKTORÃ“W")
    print("="*60)
    if sector_report:
        for sector in sector_report[:10]:  # Top 10
            print(f"{sector['sector']:20} | Score: {sector['trend_score']:+6.3f} | "
                  f"Momentum: {sector['momentum']:12} | Liczba: {sector['count']}")
    else:
        print("Brak danych dla sektorÃ³w")

    print("\n" + "="*60)
    print("RAPORT SPÃ“ÅEK (TOP 20)")
    print("="*60)
    if ticker_report:
        for ticker in ticker_report[:20]:  # Top 20
            print(f"{ticker['ticker']:10} | Score: {ticker['trend_score']:+6.3f} | "
                  f"Momentum: {ticker['momentum']:12} | Liczba: {ticker['count']}")
    else:
        print("Brak danych dla tickerÃ³w")

    print("\n" + "="*60)

    return report

if __name__ == "__main__":
    """
    PrzykÅ‚ad uÅ¼ycia:

    # Tryb 1: Analiza konkretnego artykuÅ‚u po ID
    db = Database('news.db')
    result = analyze_articles(db, mode='id', article_id=123)
    print(result)

    # Tryb 2: Analiza wszystkich nieprzeanalizowanych artykuÅ‚Ã³w
    db = Database('news.db')
    result = analyze_articles(db, mode='unanalyzed')
    print(result)
    """
    import sys
    from config import Config

    config = Config()
    db = Database(config.db_path)

    if len(sys.argv) > 1:
        if sys.argv[1] == '--id' and len(sys.argv) > 2:
            # Analiza konkretnego artykuÅ‚u
            article_id = int(sys.argv[2])
            print(f"AnalizujÄ™ artykuÅ‚ ID={article_id}...")
            result = analyze_articles(db, mode='id', article_id=article_id)
            print(result)
        elif sys.argv[1] == '--unanalyzed':
            # Analiza nieprzeanalizowanych
            print("AnalizujÄ™ nieprzeanalizowane artykuÅ‚y...")
            result = analyze_articles(db, mode='unanalyzed')
            #print(result)
        elif sys.argv[1] == '--report':
            # Generuj raport
            report = generate_report(db)
        else:
            print("UÅ¼ycie:")
            print("  python ai_analist.py --id <article_id>  # Analizuj konkretny artykuÅ‚")
            print("  python ai_analist.py --unanalyzed       # Analizuj wszystkie nieprzeanalizowane")
            print("  python ai_analist.py --report           # Generuj raport trendÃ³w")
    else:
        print("UÅ¼ycie:")
        print("  python ai_analist.py --id <article_id>  # Analizuj konkretny artykuÅ‚")
        print("  python ai_analist.py --unanalyzed       # Analizuj wszystkie nieprzeanalizowane")
        print("  python ai_analist.py --report           # Generuj raport trendÃ³w")
