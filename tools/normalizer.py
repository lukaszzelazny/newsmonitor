"""
Modu≈Ç do normalizacji ticker√≥w i zapobiegania duplikatom
"""
from sqlalchemy import create_engine, text
from difflib import SequenceMatcher
import os
import json

def get_db_engine():
    db_url = "postgresql:///?service=stock"
    engine = create_engine(db_url)
    schema = os.getenv('DB_SCHEMA', 'stock')
    return engine, schema

engine, schema = get_db_engine()

# Statyczna mapa najczƒôstszych b≈Çƒôd√≥w (backup)
TICKER_ALIASES = {
    'SYN': 'SNT',
    'KGH': 'KGHM',
    'CDP': 'CDR',
    'CD': 'CDR',
    'OPL': 'OPL',  # Orange Polska - czasem skracane
    'PKO': 'PKO',  # PKO BP - czasem bez BP
}

class TickerNormalizer:
    def __init__(self):
        self.company_to_ticker = {}  # Inicjalizuj przed _load_valid_tickers
        self.valid_tickers = self._load_valid_tickers()
        self.aliases = self._load_aliases()

    def _load_valid_tickers(self):
        """Za≈Çaduj listƒô wszystkich poprawnych ticker√≥w z bazy"""
        with engine.connect() as conn:
            result = conn.execute(text(f"""
                SELECT ticker, company_name 
                FROM {schema}.tickers
                WHERE ticker IS NOT NULL
                ORDER BY ticker
            """))
            tickers = {}

            for row in result:
                ticker = row[0]
                company = row[1]
                tickers[ticker] = company

                if company:
                    # Normalizuj nazwƒô (uppercase, bez znak√≥w diakrytycznych)
                    normalized_name = self._normalize_company_name(company)
                    self.company_to_ticker[normalized_name] = ticker

                    # Dodaj r√≥wnie≈º orygina≈Ç uppercase
                    self.company_to_ticker[company.upper()] = ticker

                    # Dodaj wersjƒô bez "S.A." / "SA"
                    company_without_sa = company.upper().replace(' S.A.', '').replace(' SA', '').strip()
                    if company_without_sa != company.upper():
                        self.company_to_ticker[company_without_sa] = ticker

            print(f"‚úì Za≈Çadowano {len(tickers)} ticker√≥w i {len(self.company_to_ticker)} mapowa≈Ñ nazw")

            return tickers

    def _normalize_company_name(self, name: str) -> str:
        """Normalizuje nazwƒô firmy (usuwa znaki diakrytyczne, etc)"""
        if not name:
            return ""

        # Mapa polskich znak√≥w
        replacements = {
            'ƒÑ': 'A', 'ƒÜ': 'C', 'ƒò': 'E', '≈Å': 'L', '≈É': 'N',
            '√ì': 'O', '≈ö': 'S', '≈π': 'Z', '≈ª': 'Z',
            'ƒÖ': 'a', 'ƒá': 'c', 'ƒô': 'e', '≈Ç': 'l', '≈Ñ': 'n',
            '√≥': 'o', '≈õ': 's', '≈∫': 'z', '≈º': 'z'
        }

        result = name.upper()
        for old, new in replacements.items():
            result = result.replace(old, new)

        # Usu≈Ñ SA, S.A., Sp√≥≈Çka Akcyjna, etc.
        result = result.replace(' S.A.', '').replace(' SA', '').replace(' S.A', '')
        result = result.replace(' SPOLKA AKCYJNA', '').replace(' SP√ì≈ÅKA AKCYJNA', '')

        return result.strip()

    def _load_aliases(self):
        """Za≈Çaduj mapƒô alias√≥w z bazy (je≈õli istnieje)"""
        try:
            with engine.connect() as conn:
                result = conn.execute(text(f"""
                    SELECT alias, canonical_ticker 
                    FROM {schema}.ticker_aliases
                """))
                return {row[0]: row[1] for row in result}
        except:
            # Tabela mo≈ºe nie istnieƒá - u≈ºyj statycznej mapy
            return TICKER_ALIASES

    def normalize(self, ticker: str, auto_add_alias=True) -> tuple[str, str]:
        """
        Normalizuje ticker do kanonicznej formy

        Args:
            ticker: Ticker lub nazwa firmy do znormalizowania
            auto_add_alias: Czy automatycznie dodaƒá alias do bazy

        Returns:
            tuple: (znormalizowany_ticker, pow√≥d_zmiany lub None)
        """
        if not ticker:
            return ticker, None

        original_ticker = ticker
        ticker = ticker.strip().upper()

        # 1. NAJPIERW sprawd≈∫ aliasy (przed valid_tickers!)
        if ticker in self.aliases:
            canonical = self.aliases[ticker]
            return canonical, f"alias: {ticker} -> {canonical}"

        # 2. Sprawd≈∫ czy ticker ju≈º jest poprawny (kr√≥tki ticker <= 6 znak√≥w)
        if ticker in self.valid_tickers and len(ticker) <= 6:
            return ticker, None

        # 3. Sprawd≈∫ czy to nazwa firmy
        # 3a. Bezpo≈õrednie dopasowanie w company_to_ticker
        if ticker in self.company_to_ticker:
            canonical = self.company_to_ticker[ticker]
            if auto_add_alias and ticker not in self.aliases and len(ticker) > 6:
                self.add_alias(ticker, canonical, silent=True)
            return canonical, f"company name: '{original_ticker}' -> {canonical}"

        # 3b. Dopasowanie znormalizowanej nazwy (bez polskich znak√≥w)
        normalized_name = self._normalize_company_name(ticker)
        if normalized_name != ticker and normalized_name in self.company_to_ticker:
            canonical = self.company_to_ticker[normalized_name]
            if auto_add_alias and ticker not in self.aliases and len(ticker) > 6:
                self.add_alias(ticker, canonical, silent=True)
            return canonical, f"company name normalized: '{original_ticker}' -> {canonical}"

        # 3c. Fuzzy match po nazwach firm (dla d≈Çugich string√≥w)
        if len(ticker) > 6:
            best_match = self._fuzzy_match_company(ticker)
            if best_match:
                if auto_add_alias and ticker not in self.aliases:
                    self.add_alias(ticker, best_match, silent=True)
                return best_match, f"fuzzy company match: '{original_ticker}' -> {best_match}"

        # 4. Fuzzy matching - znajd≈∫ najbardziej podobny ticker (dla kr√≥tkich string√≥w)
        best_match = None
        best_similarity = 0

        for valid_ticker in self.valid_tickers:
            # Pomi≈Ñ d≈Çugie tickery (prawdopodobnie b≈Çƒôdne)
            if len(valid_ticker) > 6:
                continue

            similarity = SequenceMatcher(None, ticker, valid_ticker).ratio()

            # Dodatkowe punkty je≈õli ticker jest prefiksem
            if valid_ticker.startswith(ticker) or ticker.startswith(valid_ticker):
                similarity += 0.2

            if similarity > best_similarity and similarity > 0.7:
                best_similarity = similarity
                best_match = valid_ticker

        if best_match and best_similarity > 0.8:
            if auto_add_alias and ticker not in self.aliases:
                self.add_alias(ticker, best_match, silent=True)
            return best_match, f"fuzzy ticker match: {ticker} -> {best_match} (similarity: {best_similarity:.2f})"

        # 5. Nie znaleziono - zwr√≥ƒá oryginalny (mo≈ºe to nowy ticker)
        return ticker, f"warning: nieznany ticker '{ticker}'"

    def _fuzzy_match_company(self, company_name: str) -> str:
        """Fuzzy matching dla nazw firm"""
        normalized = self._normalize_company_name(company_name)
        best_match = None
        best_similarity = 0

        for company_key, ticker in self.company_to_ticker.items():
            similarity = SequenceMatcher(None, normalized, company_key).ratio()

            # Bonus za zawieranie
            if normalized in company_key or company_key in normalized:
                similarity += 0.15

            if similarity > best_similarity and similarity > 0.75:
                best_similarity = similarity
                best_match = ticker

        return best_match if best_similarity > 0.8 else None

    def get_prompt_context(self) -> str:
        """Generuje kontekst dla AI z listƒÖ poprawnych ticker√≥w"""
        ticker_list = []

        # Grupuj po sektorach je≈õli sƒÖ dostƒôpne
        with engine.connect() as conn:
            result = conn.execute(text(f"""
                SELECT ticker, company_name, sector
                FROM {schema}.tickers
                WHERE ticker IS NOT NULL
                ORDER BY 
                    CASE WHEN in_portfolio = 1 THEN 0 ELSE 1 END,
                    sector NULLS LAST,
                    ticker
            """))

            current_sector = None
            for row in result:
                ticker, company, sector = row[0], row[1], row[2]

                # Nag≈Ç√≥wek sektora
                if sector and sector != current_sector:
                    ticker_list.append(f"\n{sector}:")
                    current_sector = sector

                ticker_list.append(f"  ‚Ä¢ {ticker} - {company or 'brak nazwy'}")

        return """
KRYTYCZNE: WALIDACJA TICKER√ìW
================================
U≈ºywaj WY≈ÅƒÑCZNIE ticker√≥w z poni≈ºszej listy. Nie wymy≈õlaj skr√≥t√≥w ani wariant√≥w!

POPRAWNE TICKERY Z GPW:
{}

CZƒòSTE B≈ÅƒòDY DO UNIKANIA:
‚Ä¢ KGHM (‚úì) NIE: KGH, KGHM.PL
‚Ä¢ SNT (‚úì) NIE: SYN, SYNEKTIK  
‚Ä¢ CDR (‚úì) NIE: CDP, CD, CDPROJEKT
‚Ä¢ OPL (‚úì) NIE: ORANGE
‚Ä¢ PKO (‚úì) NIE: PKOBP

Je≈õli nie jeste≈õ pewien tickera - u≈ºyj pe≈Çnej nazwy firmy, a system go znormalizuje.
""".format("\n".join(ticker_list))

    def add_alias(self, alias: str, canonical: str, silent=False):
        """Dodaje nowy alias do bazy"""
        with engine.connect() as conn:
            try:
                conn.execute(text(f"""
                    INSERT INTO {schema}.ticker_aliases (alias, canonical_ticker)
                    VALUES (:alias, :canonical)
                    ON CONFLICT (alias) DO UPDATE 
                    SET canonical_ticker = :canonical
                """), {'alias': alias, 'canonical': canonical})
                conn.commit()
                self.aliases[alias] = canonical
                if not silent:
                    print(f"‚úì Dodano alias: {alias} -> {canonical}")
            except Exception as e:
                if not silent:
                    print(f"‚úó B≈ÇƒÖd dodawania aliasu: {e}")

# Singleton
_normalizer = None

def get_normalizer() -> TickerNormalizer:
    """Zwraca singleton normalizera"""
    global _normalizer
    if _normalizer is None:
        _normalizer = TickerNormalizer()
    return _normalizer


# ===== SKRYPT DO CZYSZCZENIA B≈ÅƒòDNYCH TICKER√ìW =====

def clean_invalid_tickers():
    """Znajduje i naprawia b≈Çƒôdne tickery (d≈Çugie nazwy firm zapisane jako tickery)"""
    print("üîç Szukam b≈Çƒôdnych ticker√≥w (d≈Çugich nazw firm)...")

    with engine.connect() as conn:
        # Znajd≈∫ wszystkie tickery d≈Çu≈ºsze ni≈º 6 znak√≥w (prawdopodobnie nazwy firm)
        result = conn.execute(text(f"""
            SELECT DISTINCT ticker 
            FROM {schema}.tickers
            WHERE LENGTH(ticker) > 6
            ORDER BY ticker
        """))

        invalid_tickers = [row[0] for row in result]

        if not invalid_tickers:
            print("‚úì Nie znaleziono b≈Çƒôdnych ticker√≥w!")
            return

        print(f"Znaleziono {len(invalid_tickers)} podejrzanych ticker√≥w:")

        # Mapuj ka≈ºdy b≈Çƒôdny ticker do poprawnego
        mappings = []
        for invalid in invalid_tickers:
            # Spr√≥buj znale≈∫ƒá prawdziwy ticker
            # Szukaj w ticker_sentiment - jakie KR√ìTKIE tickery sƒÖ u≈ºywane dla podobnych news√≥w?
            search_result = conn.execute(text(f"""
                SELECT DISTINCT ts2.ticker, COUNT(*) as cnt
                FROM {schema}.ticker_sentiment ts1
                JOIN {schema}.analysis_result ar ON ts1.analysis_id = ar.id
                JOIN {schema}.ticker_sentiment ts2 ON ts2.analysis_id = ar.id
                WHERE ts1.ticker = :invalid
                  AND LENGTH(ts2.ticker) <= 6
                  AND ts2.ticker != ts1.ticker
                GROUP BY ts2.ticker
                ORDER BY cnt DESC
                LIMIT 1
            """), {'invalid': invalid})

            row = search_result.fetchone()
            if row:
                correct_ticker = row[0]
                mappings.append((invalid, correct_ticker))
                print(f"  {invalid:30} -> {correct_ticker}")
            else:
                print(f"  {invalid:30} -> ??? (nie znaleziono kandydata)")

        if not mappings:
            print("\n‚ö†Ô∏è  Nie mo≈ºna automatycznie zmapowaƒá ticker√≥w")
            return

        # Zapytaj o potwierdzenie
        print(f"\n‚ùì Czy zastosowaƒá {len(mappings)} poprawek? (tak/nie): ", end='')
        confirm = input().lower()

        if confirm not in ['tak', 't', 'yes', 'y']:
            print("‚ùå Anulowano")
            return

        # Wykonaj poprawki
        for invalid, correct in mappings:
            try:
                # 1. Przenie≈õ dane z ticker_sentiment
                conn.execute(text(f"""
                    UPDATE {schema}.ticker_sentiment
                    SET ticker = :correct
                    WHERE ticker = :invalid
                """), {'correct': correct, 'invalid': invalid})

                # 2. Dodaj alias
                conn.execute(text(f"""
                    INSERT INTO {schema}.ticker_aliases (alias, canonical_ticker)
                    VALUES (:invalid, :correct)
                    ON CONFLICT (alias) DO UPDATE SET canonical_ticker = :correct
                """), {'invalid': invalid, 'correct': correct})

                # 3. Usu≈Ñ b≈Çƒôdny ticker z tickers
                conn.execute(text(f"""
                    DELETE FROM {schema}.tickers
                    WHERE ticker = :invalid
                """), {'invalid': invalid})

                print(f"  ‚úì {invalid} -> {correct}")

            except Exception as e:
                print(f"  ‚úó {invalid} -> {correct}: {e}")

        conn.commit()
        print("\n‚úÖ Czyszczenie zako≈Ñczone!")

def fill_missing_company_names():
    """Pobiera brakujƒÖce nazwy firm z Yahoo Finance"""
    import yfinance as yf

    print("üîç Szukam ticker√≥w bez nazw firm...")

    with engine.connect() as conn:
        result = conn.execute(text(f"""
            SELECT ticker 
            FROM {schema}.tickers
            WHERE company_name IS NULL OR company_name = ''
            ORDER BY ticker
        """))

        tickers_without_names = [row[0] for row in result]

        if not tickers_without_names:
            print("‚úì Wszystkie tickery majƒÖ nazwy!")
            return

        print(f"Znaleziono {len(tickers_without_names)} ticker√≥w bez nazw")

        for ticker in tickers_without_names:
            try:
                # Dodaj .WA dla ticker√≥w z GPW
                yf_symbol = f"{ticker}.WA" if len(ticker) <= 4 else ticker
                yf_ticker = yf.Ticker(yf_symbol)
                info = yf_ticker.info

                company_name = (
                    info.get('longName') or
                    info.get('shortName') or
                    info.get('name')
                )

                if company_name:
                    conn.execute(text(f"""
                        UPDATE {schema}.tickers
                        SET company_name = :name
                        WHERE ticker = :ticker
                    """), {'name': company_name, 'ticker': ticker})
                    print(f"  ‚úì {ticker:6} -> {company_name}")
                else:
                    print(f"  ‚úó {ticker:6} -> Nie znaleziono nazwy")

            except Exception as e:
                print(f"  ‚úó {ticker:6} -> B≈ÇƒÖd: {e}")

        conn.commit()
        print("\n‚úÖ Uzupe≈Çnianie nazw zako≈Ñczone!")

def migrate_summary_tickers(dry_run=True):
    """
    Normalizuje tickery w polu `related_tickers` w `analysis_result.summary`
    """
    normalizer = get_normalizer()
    print("\nüîç Szukam ticker√≥w do normalizacji w `analysis_result.summary`...")

    with engine.connect() as conn:
        # U≈ºyj jsonb_path_exists dla wydajno≈õci
        # U≈ºyj standardowych operator√≥w JSON zamiast jsonb_path_exists, aby uniknƒÖƒá problem√≥w ze sk≈ÇadniƒÖ
        result = conn.execute(text(f"""
            SELECT id, summary
            FROM {schema}.analysis_result
            WHERE summary IS NOT NULL 
              AND TRIM(summary) LIKE '{{%'
              AND (summary::jsonb) ? 'related_tickers'
              AND jsonb_typeof(summary::jsonb -> 'related_tickers') = 'array'
              AND jsonb_array_length(summary::jsonb -> 'related_tickers') > 0
        """))

        updates_to_perform = []
        for id, summary_str in result:
            try:
                summary = json.loads(summary_str)
                if not isinstance(summary, dict) or 'related_tickers' not in summary or not summary['related_tickers']:
                    continue
            except json.JSONDecodeError:
                continue  # Pomi≈Ñ nieprawid≈Çowy JSON

            original_tickers = summary.get('related_tickers', [])
            normalized_tickers = []
            changed = False

            for ticker in original_tickers:
                # U≈ºyj auto_add_alias=True, aby upewniƒá siƒô, ≈ºe nowe aliasy sƒÖ rozpoznawane
                normalized, reason = normalizer.normalize(ticker, auto_add_alias=True)
                normalized_tickers.append(normalized)
                if normalized != ticker:
                    changed = True
                    print(f"  (ID: {id}) {ticker} -> {normalized} ({reason})")

            if changed:
                new_summary = summary.copy()
                new_summary['related_tickers'] = normalized_tickers
                updates_to_perform.append({'id': id, 'summary': new_summary})

        if not updates_to_perform:
            print("‚úì Nie znaleziono ticker√≥w do aktualizacji w `summary`!")
            return

        print(f"\nüìä Znaleziono {len(updates_to_perform)} rekord√≥w `analysis_result` do aktualizacji.")

        if dry_run:
            print("\n‚ö†Ô∏è  DRY RUN - ≈ºadne zmiany nie zosta≈Çy zapisane w `analysis_result`")
            return

        print("\nüîß Aktualizujƒô `analysis_result.summary`...")
        for update in updates_to_perform:
            # Serializuj s≈Çownik z powrotem do JSON string przed zapisem
            summary_json_str = json.dumps(update['summary'], ensure_ascii=False)
            conn.execute(text(f"""
                UPDATE {schema}.analysis_result
                SET summary = :summary
                WHERE id = :id
            """), {'summary': summary_json_str, 'id': update['id']})
            print(f"  ‚úì Zaktualizowano ID: {update['id']}")
        
        conn.commit()
        print("‚úÖ Aktualizacja `summary` zako≈Ñczona!")


def migrate_duplicate_tickers(dry_run=True):
    """
    Znajduje i ≈ÇƒÖczy duplikaty ticker√≥w w bazie (w ticker_sentiment)

    Args:
        dry_run: Je≈õli True, tylko pokazuje co by siƒô sta≈Ço
    """
    normalizer = get_normalizer()

    print("üîç Szukam duplikat√≥w ticker√≥w...")

    with engine.connect() as conn:
        # Znajd≈∫ wszystkie u≈ºywane tickery
        result = conn.execute(text(f"""
            SELECT DISTINCT ticker 
            FROM {schema}.ticker_sentiment
            WHERE ticker IS NOT NULL
            ORDER BY ticker
        """))

        used_tickers = [row[0] for row in result]

        duplicates = {}
        for ticker in used_tickers:
            normalized, reason = normalizer.normalize(ticker)

            if reason and normalized != ticker:
                if normalized not in duplicates:
                    duplicates[normalized] = []
                duplicates[normalized].append(ticker)
                print(f"  ‚ö†Ô∏è  {ticker} -> {normalized} ({reason})")

        if not duplicates:
            print("‚úì Nie znaleziono duplikat√≥w!")
            return

        print(f"\nüìä Znaleziono {len(duplicates)} grup duplikat√≥w:")
        for canonical, aliases in duplicates.items():
            print(f"  {canonical}: {', '.join(aliases)}")

        if dry_run:
            print("\n‚ö†Ô∏è  DRY RUN - ≈ºadne zmiany nie zosta≈Çy zapisane")
            print("Uruchom ponownie z dry_run=False aby zastosowaƒá zmiany")
            return

        # Aktualizuj tickery
        print("\nüîß Aktualizujƒô tickery...")
        for canonical, aliases in duplicates.items():
            for alias in aliases:
                # Aktualizuj ticker_sentiment
                conn.execute(text(f"""
                    UPDATE {schema}.ticker_sentiment
                    SET ticker = :canonical
                    WHERE ticker = :alias
                """), {'canonical': canonical, 'alias': alias})

                # Dodaj do aliases
                normalizer.add_alias(alias, canonical)

                print(f"  ‚úì {alias} -> {canonical}")

        conn.commit()
        print("\n‚úÖ Migracja `ticker_sentiment` zako≈Ñczona!")


if __name__ == '__main__':
    import sys

    # Obs≈Çuga argument√≥w wiersza polece≈Ñ
    if len(sys.argv) > 1:
        command = sys.argv[1]

        if command == 'clean':
            clean_invalid_tickers()
            sys.exit(0)
        elif command == 'fill-names':
            fill_missing_company_names()
            sys.exit(0)
        elif command == 'migrate':
            dry_run = '--dry-run' in sys.argv or '-n' in sys.argv
            migrate_duplicate_tickers(dry_run=dry_run)
            migrate_summary_tickers(dry_run=dry_run)
            sys.exit(0)
        elif command == 'help':
            print("""
U≈ºycie: python ticker_normalization.py [command]

Dostƒôpne komendy:
  clean         - Usu≈Ñ b≈Çƒôdne tickery (d≈Çugie nazwy firm) i przenie≈õ dane
  fill-names    - Uzupe≈Çnij brakujƒÖce nazwy firm z Yahoo Finance
  migrate       - Migruj duplikaty ticker√≥w (u≈ºyj --dry-run dla testu)
  help          - Poka≈º tƒô pomoc
  (brak)        - Uruchom testy
            """)
            sys.exit(0)

    # Test
    normalizer = get_normalizer()

    print("=== DEBUG: Przyk≈Çadowe mapowania ===\n")
    print(f"Za≈Çadowano {len(normalizer.valid_tickers)} ticker√≥w i {len(normalizer.company_to_ticker)} mapowa≈Ñ nazw")
    print("\nPierwsze 10 mapowa≈Ñ company_to_ticker:")
    for i, (name, ticker) in enumerate(list(normalizer.company_to_ticker.items())[:10]):
        print(f"  '{name}' -> {ticker}")

    # Sprawd≈∫ konkretne przypadki
    print("\n=== DEBUG: Sprawdzanie konkretnych nazw ===")
    test_names = ['≈öNIE≈ªKA', 'SNIEZKA', 'CD PROJEKT', 'KGHM POLSKA MIED≈π']
    for name in test_names:
        normalized = normalizer._normalize_company_name(name)
        in_map = name in normalizer.company_to_ticker
        in_map_normalized = normalized in normalizer.company_to_ticker
        print(f"  '{name}':")
        print(f"    normalized: '{normalized}'")
        print(f"    in map (original): {in_map}")
        print(f"    in map (normalized): {in_map_normalized}")
        if in_map:
            print(f"    -> {normalizer.company_to_ticker[name]}")
        if in_map_normalized:
            print(f"    -> {normalizer.company_to_ticker[normalized]}")

    print("\n=== TEST NORMALIZACJI ===\n")

    test_cases = [
        'KGHM',  # poprawny
        'KGH',   # alias
        'SYN',   # alias
        'SNT',   # poprawny
        'CDP',   # alias
        'CDPROJ',  # fuzzy match
        '≈öNIE≈ªKA',  # nazwa firmy z polskimi znakami
        'SNIEZKA',  # nazwa firmy bez polskich znak√≥w
        '≈önie≈ºka S.A.',  # pe≈Çna nazwa
        'CD Projekt',  # nazwa firmy
        'KGHM Polska Mied≈∫',  # pe≈Çna nazwa
        'XYZ',   # nieznany
    ]

    for test in test_cases:
        normalized, reason = normalizer.normalize(test)
        status = "‚úì" if not reason else ("‚ö†Ô∏è" if "warning" in reason else "‚Üí")
        print(f"{status} {test:25} => {normalized:10} | {reason or 'OK'}")

    print("\n=== PODPOWIEDZI ===")
    print("1. python ticker_normalization.py clean")
    print("   ‚Üí Usu≈Ñ b≈Çƒôdne tickery (d≈Çugie nazwy firm)")
    print("2. python ticker_normalization.py fill-names")
    print("   ‚Üí Uzupe≈Çnij brakujƒÖce nazwy firm z Yahoo Finance")
    print("3. python ticker_normalization.py migrate --dry-run")
    print("   ‚Üí Zobacz duplikaty do migracji")
